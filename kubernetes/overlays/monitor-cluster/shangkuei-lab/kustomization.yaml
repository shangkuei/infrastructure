---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# Monitor Cluster - shangkuei-lab
# See README.md and CLAUDE.md for documentation

resources:
  # Loki - Log aggregation (from base)
  - ../../../base/monitor-cluster
  # SOPS-encrypted secret for Loki S3 storage (SeaweedFS)
  - secret-loki-s3.enc.yaml

  # Alloy - Log collector
  - helmrelease-alloy.yaml
  - configmap-alloy.yaml

  # Grafana - Visualization (storage: emptyDir, dashboards managed via CRs)
  - grafana-grafana-cluster.yaml

  # GrafanaDatasources - Prometheus and Loki data sources
  - grafanadatasources/grafanadatasource-prometheus.yaml
  - grafanadatasources/grafanadatasource-loki.yaml

  # GrafanaDashboards - Auto-generated by: make build (in _dashboards/ directory)
  # Source: kube-prometheus jsonnet + coredns/loki/openebs/alloy/cilium/cert-manager mixins
  - grafanadashboards/grafanadashboard-alloy.yaml
  - grafanadashboards/grafanadashboard-cert-manager.yaml
  - grafanadashboards/grafanadashboard-cilium.yaml
  - grafanadashboards/grafanadashboard-coredns.yaml
  - grafanadashboards/grafanadashboard-grafana.yaml
  - grafanadashboards/grafanadashboard-kubernetes.yaml
  - grafanadashboards/grafanadashboard-loki.yaml
  - grafanadashboards/grafanadashboard-node-exporter.yaml
  - grafanadashboards/grafanadashboard-openebs.yaml
  - grafanadashboards/grafanadashboard-prometheus.yaml
  # External dashboards - Generated by: ./_dashboards/build-external-dashboards.sh
  - grafanadashboards/grafanadashboard-flux.yaml
  - grafanadashboards/grafanadashboard-seaweedfs.yaml
  # Resource optimization dashboards
  - grafanadashboards/grafanadashboard-vpa.yaml
  - grafanadashboards/grafanadashboard-metrics-server.yaml
  - grafanadashboards/grafanadashboard-kubelet-cert-approver.yaml
  # Infrastructure dashboards
  - grafanadashboards/grafanadashboard-cloudflared.yaml
  - grafanadashboards/grafanadashboard-docker-containers.yaml
  - grafanadashboards/grafanadashboard-unraid-nas.yaml

  # Prometheus - Metrics collection
  - prometheus-cluster.yaml
  - serviceaccount-prometheus.yaml
  - clusterrole-prometheus.yaml
  - clusterrolebinding-prometheus.yaml
  - service-prometheus.yaml
  - persistentvolumeclaim-prometheus-cluster.yaml

  # Alertmanager - Alert routing
  - alertmanager-cluster.yaml
  - serviceaccount-alertmanager.yaml
  - clusterrole-alertmanager.yaml
  - clusterrolebinding-alertmanager.yaml
  - service-alertmanager.yaml

  # PrometheusRules - Recording and alerting rules
  # Auto-generated by: make build (in _dashboards/ directory)
  # Source: kube-prometheus jsonnet + coredns/loki/openebs/alloy/cilium/cert-manager mixins
  - prometheusrules/prometheusrule-alertmanager.yaml
  - prometheusrules/prometheusrule-alloy.yaml
  - prometheusrules/prometheusrule-cert-manager.yaml
  - prometheusrules/prometheusrule-cilium.yaml
  - prometheusrules/prometheusrule-coredns.yaml
  - prometheusrules/prometheusrule-kube-prometheus.yaml
  - prometheusrules/prometheusrule-kube-state-metrics.yaml
  - prometheusrules/prometheusrule-kubernetes-control-plane.yaml
  - prometheusrules/prometheusrule-loki.yaml
  - prometheusrules/prometheusrule-node-exporter.yaml
  - prometheusrules/prometheusrule-openebs.yaml
  - prometheusrules/prometheusrule-prometheus.yaml
  - prometheusrules/prometheusrule-prometheus-operator.yaml
  # Unraid-specific alerts for Docker host
  - prometheusrules/prometheusrule-unraid.yaml

  # PodMonitors - Scrape configurations for pods without services
  - podmonitors/podmonitor-flux.yaml
  - podmonitors/podmonitor-cloudflared.yaml

  # ServiceMonitors - Scrape configurations
  - servicemonitors/servicemonitor-alertmanager.yaml
  - servicemonitors/servicemonitor-apiserver.yaml
  - servicemonitors/servicemonitor-controller-manager.yaml
  - servicemonitors/servicemonitor-coredns.yaml
  - servicemonitors/servicemonitor-grafana.yaml
  - servicemonitors/servicemonitor-kubelet.yaml
  - servicemonitors/servicemonitor-openebs.yaml
  - servicemonitors/servicemonitor-operator.yaml
  - servicemonitors/servicemonitor-prometheus.yaml
  - servicemonitors/servicemonitor-scheduler.yaml
  - servicemonitors/servicemonitor-seaweedfs.yaml

labels:
  - pairs:
      app.kubernetes.io/instance: shangkuei-lab
      app.kubernetes.io/environment: lab

# Loki configuration - S3 storage with SeaweedFS backend
patches:
  - patch: |-
      # Override cluster label for recording rules and dashboards
      # Without this, recording rules use "loki" as cluster label
      - op: add
        path: /spec/values/clusterLabelOverride
        value: shangkuei-lab
      - op: add
        path: /spec/values/loki
        value:
          # Schema configuration
          schemaConfig:
            configs:
              - from: "2024-01-01"
                store: tsdb
                object_store: s3
                schema: v13
                index:
                  prefix: index_
                  period: 24h
          # S3 storage configuration (SeaweedFS)
          storage:
            type: s3
            s3:
              endpoint: http://seaweedfs-filer.seaweedfs.svc.cluster.local:8333
              s3ForcePathStyle: true
              insecure: true
            bucketNames:
              chunks: loki
              ruler: loki
              admin: loki
          # Use existing secret for S3 credentials
          storage_config:
            aws:
              s3forcepathstyle: true
      # Configure read/write/backend replicas with resources based on actual usage
      - op: add
        path: /spec/values/read
        value:
          replicas: 2
          persistence:
            storageClass: openebs-mayastor
            size: 10Gi
          # Actual usage: 11-14m CPU, 209-214Mi memory
          resources:
            requests:
              cpu: 25m
              memory: 256Mi
            limits:
              cpu: 200m
              memory: 512Mi
      - op: add
        path: /spec/values/write
        value:
          replicas: 2
          persistence:
            storageClass: openebs-mayastor
            size: 10Gi
          # Actual usage: 20-22m CPU, 153-155Mi memory
          resources:
            requests:
              cpu: 50m
              memory: 256Mi
            limits:
              cpu: 200m
              memory: 512Mi
      - op: add
        path: /spec/values/backend
        value:
          replicas: 2
          persistence:
            storageClass: openebs-mayastor
            size: 10Gi
          # Actual usage: 5-6m CPU, 155-156Mi memory
          resources:
            requests:
              cpu: 25m
              memory: 256Mi
            limits:
              cpu: 200m
              memory: 512Mi
      # Gateway configuration
      - op: add
        path: /spec/values/gateway
        value:
          replicas: 1
          # Actual usage: 4m CPU, 18Mi memory
          resources:
            requests:
              cpu: 25m
              memory: 64Mi
            limits:
              cpu: 100m
              memory: 128Mi
      # Chunked encoding for S3
      - op: add
        path: /spec/values/chunksCache
        value:
          enabled: false
      # Results cache - reduced from 1024MB to 128MB (actual usage: 31Mi)
      - op: add
        path: /spec/values/resultsCache
        value:
          allocatedMemory: 128
          resources:
            requests:
              cpu: 25m
              memory: 256Mi
            limits:
              cpu: 200m
              memory: 512Mi
      # Disable minio (we use SeaweedFS)
      - op: add
        path: /spec/values/minio
        value:
          enabled: false
      # Loki Canary resources (VPA target: 15m/32Mi, actual: 1-7m/16-19Mi)
      - op: add
        path: /spec/values/lokiCanary
        value:
          resources:
            requests:
              cpu: 15m
              memory: 32Mi
            limits:
              cpu: 100m
              memory: 64Mi
      # Compactor: enable retention processing
      - op: add
        path: /spec/values/loki/compactor
        value:
          retention_enabled: true
          retention_delete_delay: 2h
          delete_request_store: s3
      # Limits: retention 31 days, deletion API, query tuning
      # Note: deletion_mode moved from compactor to limits_config in Loki 3.x
      - op: add
        path: /spec/values/loki/limits_config
        value:
          retention_period: 744h
          deletion_mode: filter-and-delete
          max_query_parallelism: 32
          max_query_series: 10000
      # Enable ServiceMonitor for Prometheus scraping (required for Loki dashboards)
      # Note: Path is monitoring.serviceMonitor, not serviceMonitor
      - op: add
        path: /spec/values/monitoring/serviceMonitor
        value:
          enabled: true
          labels:
            release: kube-prometheus-stack
            prometheus.io/scrape-by: alloy
          # Relabelings to set cluster label for dashboard compatibility
          # Note: job label is already in namespace/service format (e.g., monitoring/loki-backend)
          #       from the ServiceMonitor, no modification needed
          relabelings:
            # Set cluster label for multi-cluster support
            - targetLabel: cluster
              replacement: shangkuei-lab
          # Loki cardinality reduction (~9.9K â†’ ~2K series)
          # Preserve only metrics used by Loki dashboards (simple-scalable mode)
          metricRelabelings:
            # Override cluster label from "loki" to "shangkuei-lab" for dashboard compatibility
            - sourceLabels: [cluster]
              targetLabel: cluster
              replacement: shangkuei-lab
            # Drop internal histogram buckets not used in dashboards (~5K series)
            # Keep: loki_request_duration_seconds (recording rules), loki_s3_request_duration_seconds (S3 latency),
            #       loki_ingester_chunk_*, loki_boltdb_shipper_*
            - sourceLabels: [__name__]
              action: drop
              regex: loki_(response_message_bytes|request_message_bytes|logql_querystats_.*|index_request_duration_seconds|kv_request_duration_seconds|cache_value_size_bytes|frontend_query_range_duration_seconds|ingester_client_request_duration_seconds|index_gateway_request_duration_seconds|cache_request_duration_seconds|tsdb_shipper_.*|log_flushes|bytes_per_line)_bucket
            # Drop internal metrics not used in dashboards
            - sourceLabels: [__name__]
              action: drop
              regex: loki_(ring_.*|inflight_requests|bloom_.*)
            # Drop canary metrics (testing only)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_canary_.*
            # Drop memberlist/gossip metrics (internal)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_memberlist_.*
            # Drop query frontend/scheduler internals (not in simple-scalable dashboards)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_(query_frontend_.*|query_scheduler_.*|querier_.*)
            # Drop rate store metrics (rate limiting internals)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_rate_store_.*
            # Drop index gateway metrics (internal)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_index_gateway_.*
            # Drop WAL and checkpoint metrics (not used)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_ingester_(wal_.*|checkpoint_.*)
            # Drop Kafka distributor metrics (not using Kafka)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_distributor_kafka_.*
            # Drop store and cache metrics (internal)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_(store_.*|cache_.*|memcache_.*)
            # Drop Azure blob metrics (not using Azure)
            - sourceLabels: [__name__]
              action: drop
              regex: loki_azure_.*
      # Disable Loki helm chart recording rules and alerts
      # We deploy loki-mixin rules instead (monitor-cluster/loki-mixin-recording-rules.yaml)
      # which include the cluster dimension required by loki-mixin dashboards
      - op: add
        path: /spec/values/monitoring/rules
        value:
          enabled: false
          alerting: false
      # Configure S3 credentials from secret
      - op: add
        path: /spec/valuesFrom
        value:
          - kind: Secret
            name: loki-s3-credentials
            valuesKey: access_key_id
            targetPath: loki.storage.s3.accessKeyId
          - kind: Secret
            name: loki-s3-credentials
            valuesKey: access_key_secret
            targetPath: loki.storage.s3.secretAccessKey
    target:
      kind: HelmRelease
      name: loki
