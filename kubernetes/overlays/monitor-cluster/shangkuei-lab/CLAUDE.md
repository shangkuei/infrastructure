# Monitor Cluster - AI Agent Guide

This document provides guidance for AI agents working with the monitoring stack configuration.

## Quick Reference

### File Naming Convention

```
{kind}-{name}.yaml
```

- **kind**: Lowercase Kubernetes kind (e.g., `prometheus`, `service`, `configmap`)
- **name**: The resource's `metadata.name`
- **CRD kinds**: Use lowercase without hyphens (e.g., `grafanadatasource`, `prometheusrule`, `servicemonitor`)

### Label Requirements

All resources MUST include:

```yaml
metadata:
  labels:
    app.kubernetes.io/name: <component>        # prometheus, alertmanager, grafana, alloy
    app.kubernetes.io/instance: <instance>     # CR name or identifier
    app.kubernetes.io/part-of: monitoring      # Always "monitoring"
    app.kubernetes.io/managed-by: kustomize    # Always "kustomize"
```

**DO NOT use these legacy Helm labels:**

- `app: kube-prometheus-stack-*`
- `chart: *`
- `heritage: Helm`
- `release: *`

### Selector Dependencies

**CRITICAL**: These selectors control resource discovery:

| Resource Type | Selected By | Required Label |
|--------------|-------------|----------------|
| ServiceMonitor | Prometheus | `app.kubernetes.io/managed-by: kustomize` |
| PrometheusRule | Prometheus | `app.kubernetes.io/managed-by: kustomize` |
| GrafanaDashboard | Grafana | `instanceSelector.matchLabels.dashboards: grafana` |
| GrafanaDatasource | Grafana | `instanceSelector.matchLabels.datasources: grafana` |

## Common Tasks

### Adding a ServiceMonitor

1. Create file: `servicemonitors/servicemonitor-{name}.yaml`
2. Template:

```yaml
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: {name}
  namespace: monitoring
  labels:
    app.kubernetes.io/name: {component}
    app.kubernetes.io/instance: {name}
    app.kubernetes.io/part-of: monitoring
    app.kubernetes.io/managed-by: kustomize
spec:
  endpoints:
    - port: metrics
      path: /metrics
      relabelings:
        - action: replace
          replacement: shangkuei-lab
          targetLabel: cluster
  namespaceSelector:
    matchNames:
      - {namespace}
  selector:
    matchLabels:
      app.kubernetes.io/name: {target-app}
```

3. Add to `kustomization.yaml` under resources

### Adding a PrometheusRule

1. Create file: `prometheusrules/prometheusrule-{name}.yaml`
2. Template:

```yaml
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {name}
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: cluster
    app.kubernetes.io/part-of: monitoring
    app.kubernetes.io/managed-by: kustomize
spec:
  groups:
    - name: {group-name}
      rules:
        - alert: {AlertName}
          expr: {promql}
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: {summary}
            description: {description}
```

3. Add to `kustomization.yaml` under resources

### Adding a GrafanaDashboard

1. Add to `dashboards/dashboards.jsonnet`
2. Run: `cd dashboards && make build`
3. Generated file: `grafanadashboard-kube-prometheus.yaml`

For manual dashboards:

```yaml
---
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDashboard
metadata:
  name: {name}
  namespace: monitoring
spec:
  instanceSelector:
    matchLabels:
      dashboards: grafana
  folder: "{folder}"
  resyncPeriod: 24h
  json: |
    { ... dashboard JSON ... }
```

### Modifying Prometheus/Alertmanager

Key files:

- `prometheus-cluster.yaml` - Prometheus CR
- `alertmanager-cluster.yaml` - Alertmanager CR

Important spec fields:

- `spec.retention` - Data retention period
- `spec.retentionSize` - Max storage size
- `spec.resources` - CPU/memory limits
- `spec.storage.volumeClaimTemplate` - PVC spec

### Modifying Grafana

Key files:

- `grafana-grafana-cluster.yaml` - Grafana CR (storage: emptyDir)

Admin credentials are auto-generated by grafana-operator in secret:
`grafana-cluster-admin-credentials`

The Grafana instance uses labels for dashboard/datasource discovery:

```yaml
metadata:
  labels:
    dashboards: grafana    # For GrafanaDashboard selector
    datasources: grafana   # For GrafanaDatasource selector
```

## Validation

Before committing changes:

```bash
# Validate kustomization
kustomize build . | kubectl apply --dry-run=client -f -

# Check for label consistency
grep -r "app.kubernetes.io/managed-by" . | grep -v kustomize

# Verify selectors match
grep -r "release:" . | grep -v ".md"  # Should be empty (no helm labels)
```

## File Inventory

### Core Components

| File | Kind | Name | Purpose |
|------|------|------|---------|
| prometheus-cluster.yaml | Prometheus | cluster | Metrics collection |
| alertmanager-cluster.yaml | Alertmanager | cluster | Alert routing |
| grafana-grafana.yaml | Grafana | grafana | Visualization |

### RBAC

| File | Kind | Name |
|------|------|------|
| serviceaccount-prometheus.yaml | ServiceAccount | prometheus |
| serviceaccount-alertmanager.yaml | ServiceAccount | alertmanager |
| clusterrole-prometheus.yaml | ClusterRole | prometheus |
| clusterrole-alertmanager.yaml | ClusterRole | alertmanager |
| clusterrolebinding-prometheus.yaml | ClusterRoleBinding | prometheus |
| clusterrolebinding-alertmanager.yaml | ClusterRoleBinding | alertmanager |

### Services

| File | Kind | Name | Port |
|------|------|------|------|
| service-prometheus.yaml | Service | prometheus | 9090 |
| service-alertmanager.yaml | Service | alertmanager | 9093 |

### Storage

| File | Kind | Name | Size |
|------|------|------|------|
| persistentvolumeclaim-prometheus-cluster.yaml | PVC | prometheus-cluster-db-... | 200Gi |

Note: Grafana uses emptyDir (ephemeral). Dashboards are managed via GrafanaDashboard CRs.

### Grafana Resources

| File | Kind | Name |
|------|------|------|
| grafanadatasource-prometheus.yaml | GrafanaDatasource | prometheus |
| grafanadatasource-loki.yaml | GrafanaDatasource | loki |
| grafanadashboard-kube-prometheus.yaml | GrafanaDashboard | (multiple) |

## Troubleshooting

### Dashboards not appearing in Grafana

1. Check GrafanaDashboard CR status: `kubectl get grafanadashboards -n monitoring`
2. Verify instanceSelector matches Grafana labels
3. Check grafana-operator logs

### Prometheus not scraping targets

1. Check ServiceMonitor has `app.kubernetes.io/managed-by: kustomize` label
2. Verify target Service exists and has matching labels
3. Check Prometheus targets UI: http://prometheus:9090/targets

### Alerts not firing

1. Verify PrometheusRule has `app.kubernetes.io/managed-by: kustomize` label
2. Check Prometheus rules UI: http://prometheus:9090/rules
3. Verify Alertmanager is receiving alerts

## Related Documentation

- [README.md](README.md) - Human-readable documentation
- [dashboards/README.md](dashboards/README.md) - Dashboard generation guide
- [../../../base/monitor-operator/README.md](../../../base/monitor-operator/README.md) - Operator deployment
