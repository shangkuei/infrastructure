---
# Grafana Alloy - Unified telemetry collector
#
# Features:
# - Metrics collection via ServiceMonitor/PodMonitor discovery (push to Prometheus)
# - Log collection from all pods (push to Loki)
#
# Architecture:
# - DaemonSet deployment (one per node)
# - Discovers ServiceMonitors/PodMonitors via Kubernetes API
# - Discovers pods for log collection via Kubernetes API
# - Clustering enabled for distributed scraping
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: alloy
  namespace: monitoring
spec:
  interval: 30m
  timeout: 10m
  chart:
    spec:
      chart: alloy
      version: ">=0.10.0 <1.0.0"
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
      interval: 12h

  install:
    createNamespace: false
    remediation:
      retries: 3

  upgrade:
    remediation:
      retries: 3
      remediateLastFailure: true
    cleanupOnFail: true

  driftDetection:
    mode: warn

  values:
    # Deploy as DaemonSet (one collector per node)
    alloy:
      configMap:
        create: false
        name: alloy-config
        key: config.alloy
      # Enable clustering for distributed scraping (prevents duplicate scrapes)
      # Clustering uses the default HTTP port (12345) for gossip communication
      clustering:
        enabled: true
      # Mount host paths into Alloy container
      mounts:
        extra:
          - name: varlog
            mountPath: /var/log
            readOnly: true
      # Resource limits for collector pods (metrics + logs collection)
      # Based on actual usage: 18-109m CPU, 265-501Mi memory
      resources:
        limits:
          cpu: 500m
          memory: 1Gi
        requests:
          cpu: 150m
          memory: 512Mi

    controller:
      type: daemonset
      # Allow running on control plane nodes
      tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
          effect: NoSchedule
      # Add host volumes for log collection
      volumes:
        extra:
          - name: varlog
            hostPath:
              path: /var/log

    # Enable ServiceMonitor for Alloy self-monitoring
    serviceMonitor:
      enabled: true
      additionalLabels:
        prometheus.io/scrape-by: alloy
      interval: 30s
      relabelings:
        - action: replace
          replacement: shangkuei-lab
          targetLabel: cluster
